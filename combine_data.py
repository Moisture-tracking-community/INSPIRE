from pathlib import Path

import xarray as xr

from Functions import grid_cell_area


def read_wam2layers(basedir):
    """Read data for WAM2layers."""
    path = basedir / "results WAM2layers"
    filename_pattern = "backtrack_*T00-00.nc"

    # Data loading this way gives an error message for me while plotting, but in principe it should work
    dsall = xr.open_mfdataset(
        path.glob(filename_pattern),
        combine="nested",
        concat_dim="time",
    ).rename(latitude="lat", longitude="lon")

    # Convert units
    # TODO might not be necessary with latest version of data, see
    # https://github.com/WAM2layers/Moisture_tracking_intercomparison/issues/43
    lat = dsall.lat.values
    lon = dsall.lon.values

    a_gridcell_new = grid_cell_area(lat, lon)
    E_track_totalmm = (dsall / a_gridcell_new) * 1000  # mm
    srcs_wam2layers_new = E_track_totalmm["e_track"].sum("time")  # mm

    return srcs_wam2layers_new.rename("wam2layers")


def read_wrf_wvt(basedir):
    raise NotImplementedError("Not availabe as netCDF due to nature of simulations.")


def read_uvigo(basedir):
    """Read data from University of Vigo"""
    path = basedir / "results Uvigo"
    return xr.Dataset(
        {
            "Vigo_e2_Sodemann": xr.open_dataarray(path / "ERA5_SJ05_reg.nc"),
            "Vigo_e1_Stohl": xr.open_dataarray(path / "ERA5_APA22_reg.nc"),
        }
    )


def read_utrack(basedir):
    """Read data from UTRACK.

    Data is generated by Arie Staal.

    Based on the communication with Arie the
    results should be area corrected. Given the values I assumed that the area
    needs to be in km**2, however this should be checked.
    """
    # TODO check units with Arie
    n_gridcells_pakistan = (71 - 67) / 0.25 * (30 - 24) / 0.25

    path = basedir / "results Utrack Arie Staal/moisture_tracking_intercomparsion"

    ensemble_members = {
        "utrack_e1": path.glob("*_mixing48h_dt025h_100p.nc"),
        "utrack_e2": path.glob("*_mixing24h_dt025h_100p.nc"),
        "utrack_e3": path.glob("*_mixing12h_dt025h_100p.nc"),
        "utrack_e4": path.glob("*_mixing24h_dt025h_1000p.nc"),
        "utrack_e5": path.glob("*_mixing24h_dt010h_100p.nc"),
    }

    ensemble = {}
    for member, files in ensemble_members.items():
        ensemble[member] = (
            xr.open_mfdataset(
                files,
                combine="nested",
                concat_dim="time",
            )["moisture_source"].sum("time")
            * n_gridcells_pakistan
        )

    return xr.Dataset(ensemble)


def read_ughent(basedir):
    """Read data from university of Ghent.

    Generated with HAMSTER.
    """
    path = basedir / "results UGhent HAMSTER/Pakistan simulations/bias_corrected"
    filename_pattern = "bias_corrected_202208*120000_{ensemble}.nc"

    ensemble_members = {
        "ghent_e1": "ens1_sod08",
        "ghent_e2": "ens2_fas19",
        "ghent_e3": "ens3_rh20",
        "ghent_e4": "ens4_allabl",
        "ghent_e5": "ens5_rhadap80",
    }

    ensemble = {}
    for name, ens in ensemble_members.items():
        files = (path / ens).glob(filename_pattern.format(ensemble=ens[5:]))
        ensemble[name] = xr.open_mfdataset(
            files, combine="nested", concat_dim="time"
        ).sum("time")["E2P_BC"]

    return xr.Dataset(ensemble)


def read_tracmass(basedir):
    """Read tracmass data.

    Data supplied by Dipanjan Dey
    Units in mm/day, so multiplied with # of event days.
    """
    nrdays = 15
    path = basedir / "results TRACMASS Dipanjan Dey"

    ds = xr.open_dataset(
        path / "TRACMASS_diagnostics.nc"
    )  # Evaporative sources (and preicp?) mm/day

    # Not used, but good to know it's available.
    # ds_pr_TRACMASS = xr.open_dataset(
    #     path / "PR_ERA5_TRACMASS.nc"
    # )  # Precip ERA5 and TRACMASS Comparison

    # convert to -180 to 180 lon
    ds.coords["lon"] = (ds.coords["lon"] + 180) % 360 - 180
    ds = ds.sortby(ds.lon)

    # Units of data is mm/day but we want mm over whole time period
    return ds["E_TRACMASS"].rename("TRACMASS") * nrdays


def read_flexpart_tatfancheng(basedir):
    """Read flexpart data from tatfancheng.

    Generated with FLEXPART-Watersip
    """
    path = basedir / "results FLEXPART_WaterSip_TatFanCheng"
    filename = "WaterSip_Cb_20220810-20220824_Pakistan_box.nc"

    ds = xr.open_dataset(path / filename)

    # convert to -180 to 180 lon
    ds.coords["lon"] = (ds.coords["lon"] + 180) % 360 - 180

    # Use TRACMASS to sort
    ds_TRACMASS = read_tracmass(basedir)
    ds = ds.sortby(ds_TRACMASS.lon)
    srcs_flexpart_tatfancheng = ds.sum("time")["Cb"]

    return srcs_flexpart_tatfancheng.rename("flexpart_tatfancheng")


def read_flexpart_xu(basedir):
    """Read flexpart data from Xu."""
    path = basedir / "results Ru_Xu_FLEXPART"
    filename = "e_daily.nc"

    # Load, rename coords, select variable, and accumulate over time
    return (
        xr.open_dataset(path / filename)["variable"]
        .rename(latitude="lat", longitude="lon")
        .sum("time")
        .rename("flexpart_xu")
    )


def read_lagranto_chc(basedir):
    """Read lagranto CHc data."""
    path = basedir / "results CHc LAGRANTO"
    filename = "Pakistan_2022_CHc_eventtotal_ens1.nc"

    # Use TRACMASS to get coordinate values
    ds_TRACMASS = read_tracmass(basedir)

    return (
        xr.open_dataset(path / filename)
        .rename(dimx_N="lon", dimy_N="lat")["N"]
        .sum("time")
        .squeeze()
        .assign_coords(lat=ds_TRACMASS.lat[::-1], lon=ds_TRACMASS.lon)
        .rename("lagranto_CHc")
    )


def read_flexpart_univie(basedir):
    """Read data for Flexpart UniVie."""
    path = basedir / "results univie FLEXPART"
    filename = "pakistan_univie.nc"

    ds = xr.open_dataset(path / filename).sum("time")
    combined = ds["moisture_uptakes_bl"] + ds["moisture_uptakes_ft"]

    return combined.rename("flexpart_univie")


def read_2ldrm(basedir):
    """Read data for 2ldrm."""
    path = basedir / "results 2LDRM"
    filename = "2LDRM_Pakistan_case_gl.nc"

    return (
        xr.open_dataset(path / filename)
        .rename(latitude="lat", longitude="lon")["moisture_source"]
        .sum("time")
        .T.rename("2ldrm")
    )


def read_flexpart_uib(basedir):
    """Read data for flexpart uib."""
    path = basedir / "results UiB FLEXPART WaterSip"
    filename = "Pakistan_2022_UiB_Sodemann_grid_EN1_regridded.nc"
    return xr.open_dataset(path / filename)["moisture_uptakes"].rename("flexpart_uib")


def read_data_pakistan(basedir):
    """Examples of data loading of moisture sources

    Data is loaded per individual ensemble member for each model.
    All data is converted to mm evaporative sources over the whole time period

    # TODO: I think this comment is outdated, right?
    WRF-WVT is not included yet, as well CHc Lagranto and univie FLEXPART

    There might also be a few (new) ensemble members not included yet:
    - For the HAMSTER model (Ughent) there is an additional ensemble member not included yet
    - Extra ensemble members of Flexpart-Watersip produced by Fandy
    """
    # Combine cumulative moisture sources for all models in one netcdf
    basedir = Path(basedir)

    return xr.merge(
        [
            # TODO: uncomment after editing (don't have the latest data atm)
            # read_2ldrm(basedir),
            # read_flexpart_uib(basedir),
            read_lagranto_chc(basedir),
            read_flexpart_xu(basedir),
            read_flexpart_tatfancheng(basedir),
            read_tracmass(basedir),
            read_ughent(basedir),
            read_utrack(basedir),
            read_uvigo(basedir),
            read_wam2layers(basedir),
        ]
    )
