"""Combine data.

This module contains functionality for reading the data contributed to the
comparison. Each contributed dataset has can be loaded with its own function.
There is also a function `read_data_pakistan` that reads data for all models in
one go.

Each data reading function gets the base directory as a pathlib Path object, and
should return an xarray dataset, with one or more variables that carry the name(s)
of the model/method or ensemble members.
"""

from pathlib import Path

import numpy as np
import xarray as xr
import glob

from Functions import grid_cell_area,get_grid_info_new


def read_wam2layers(basedir, casename):
    """Read data for WAM2layers."""
    print(f"Loading wam2layers data for {casename}")
    path = basedir / casename / "results WAM2layers"
    filename_pattern = "backtrack_*T00-00.nc"

    ds = (
        xr.open_mfdataset(
            path.glob(filename_pattern),
            combine="nested",
            concat_dim="time",
        )["e_track"]
        .rename(latitude="lat", longitude="lon")
        .sum("time")
        .rename("WAM2layers")
    )

    if casename == "Pakistan":
        # Convert units
        # TODO might not be necessary with latest version of data, see
        # https://github.com/WAM2layers/Moisture_tracking_intercomparison/issues/43
        return ds / grid_cell_area(ds.lat, ds.lon) * 1000
    else:
        return ds


def read_wrf_wvt(basedir, casename):
    print(
        "Skipping wrf_wvt data for {casename} as it is not available in gridded form."
    )


def read_uvigo(basedir, casename):
    """Read data from University of Vigo"""
    print(f"Loading uvigo data for {casename}")

    path = basedir / casename / "results Uvigo"
    return xr.Dataset(
       {
       "FLEXPART-LATTIN (UVigo)": xr.open_dataarray(path / "ERA5_APA22_reg.nc"),
       "FLEXPART-Stohl (UVigo)": xr.open_dataarray(path / "ERA5_SJ05_reg.nc"),
        }
     )
    

def read_utrack(basedir, casename):
    """Read data from UTRACK.

    Data is generated by Arie Staal.

    Based on the communication with Arie the
    results should be area corrected. Given the values I assumed that the area
    needs to be in km**2, however this should be checked.
    """
    print(f"Loading utrack data for {casename}")
    # TODO check units with Arie
    
    n_gridcells_cases = {
    	'Pakistan': (71 - 67) / 0.25 * (30 - 24) / 0.25,
    	'Australia': (158 - 149) / 0.25 * (-22 - -32) / 0.25, 
      	'Scotland': (-1 - -8) / 0.25 * (60 - 52) / 0.25  
      	}  	
    path = basedir / casename / "results Utrack Arie Staal/"

    if casename == "Pakistan":
        path = path / "moisture_tracking_intercomparsion"

    ensemble_members = {
        "UTrack Ens1": path.glob("*_mixing48h_dt025h_100p.nc"),
        "UTrack Ens2": path.glob("*_mixing24h_dt025h_100p.nc"),
        "UTrack Ens3": path.glob("*_mixing12h_dt025h_100p.nc"),
        "UTrack Ens4": path.glob("*_mixing24h_dt025h_1000p.nc"),
        "UTrack Ens5": path.glob("*_mixing24h_dt010h_100p.nc"),
    }

    ensemble = {}
    for member, files in ensemble_members.items():
        ensemble[member] = xr.open_mfdataset(
            files,
            combine="nested",
            concat_dim="time",
        )["moisture_source"].sum("time")
 
    return xr.Dataset(ensemble) * n_gridcells_cases[casename]

def read_ughent(basedir, casename):
    """Read data from university of Ghent.

    Generated with HAMSTER.
    """
    print(f"Loading ughent data for {casename}")
    path = (
        basedir
        / casename
        / f"results UGhent HAMSTER/{casename} simulations/bias_corrected"
    )
    filename_pattern = "bias_corrected_*_{ensemble}.nc"

    ensemble_members = {
        "FLEXPART-HAMSTER Ens1": "ens1_sod08",
        "FLEXPART-HAMSTER Ens2": "ens2_fas19",
        "FLEXPART-HAMSTER Ens3": "ens3_rh20",
        "FLEXPART-HAMSTER Ens4": "ens4_allabl",
        "FLEXPART-HAMSTER Ens5": "ens5_rhadap80",
    }

    ensemble = {}
    for name, ens in ensemble_members.items():
        files = (path / ens).glob(filename_pattern.format(ensemble=ens[5:]))
        ensemble[name] = xr.open_mfdataset(
            files, combine="nested", concat_dim="time"
        ).sum("time")["E2P_BC"]

    return xr.Dataset(ensemble)


def read_tracmass(basedir, casename):
    """Read tracmass data.

    Data supplied by Dipanjan Dey
    Units in mm/day, so multiplied with # of event days.
    """
    if casename == "Australia":
        filename = "TRACMASS_evap_sources_22-28feb2022.nc"
        nrdays = 7
    elif casename == "Pakistan":
        filename = "TRACMASS_diagnostics.nc"
        nrdays = 15
    elif casename == "Scotland":
        filename = "TRACMASS_evap_sources_06-08oct2023.nc"  
        nrdays = 3

    print(f"Loading tracmass data for {casename}")

    path = basedir / casename / "results TRACMASS Dipanjan Dey"
    ds = xr.open_dataset(path / filename)  # Evaporative sources (and preicp?) mm/day
    
    # convert to -180 to 180 lon
    ds.coords["lon"] = (ds.coords["lon"] + 180) % 360 - 180
    ds = ds.sortby(ds.lon)

    # Units of data is mm/day but we want mm over whole time period
    return ds["E_TRACMASS"].rename("TRACMASS") * nrdays


def read_flexpart_tatfancheng(basedir, casename):
    """Read flexpart data from tatfancheng.

    Generated with FLEXPART-Watersip
    """
    print(f"Loading tatfancheng data for {casename}")
    path = basedir / casename / "results FLEXPART_WaterSip_TatFanCheng"

    if casename == "Scotland":
        date = "20231006-20231008"
    elif casename == "Australia":
        date = "20220222-20220228"
    else:
        date = "20220810-20220824"

    ensemble_members = ["Ens1", "Ens2", "Ens3"]
    ensemble = {}
    for member in ensemble_members:
        filename = f"WaterSip_moisture_source_{casename}_{date}_{member}.nc"
        ds = xr.open_dataset(path / filename)
        # convert to -180 to 180 lon
        ds["lon"] = (ds["lon"] + 180) % 360 - 180
        ensemble[f"FLEXPART-WaterSip (TFC) {member}"] = ds.sortby(ds.lon)["Cb"]

    return xr.Dataset(ensemble)


def read_flexpart_xu(basedir, casename):
    """Read flexpart data from Xu."""
    print(f"Loading xu data for {casename}")
    path = basedir / casename / "results Ru_Xu_FLEXPART"

    if casename == "Pakistan":
        filename = "e_daily.nc"
    elif casename == "Australia":
        filename = "aus_e_daily.nc"
    elif casename == "Scotland":
        filename = "scot_e_daily.nc"

    # Load, rename coords, select variable, and accumulate over time
    return (
        xr.open_dataset(path / filename)["data"]
        .sum("time")
        .rename("FLEXPART-WaterSip (Xu)")
    )


def read_lagranto_chc(basedir, casename):
    """Read lagranto CHc data."""
    print(f"Loading CHc data for {casename}")
    path = basedir / casename / "results CHc LAGRANTO"
   
    if casename == "Pakistan":
        loncase = 180
        year = 2022
    elif casename == "Australia":
        loncase = 180.1
        year = 2022
    elif casename == "Scotland":
        loncase = 180.1
        year = 2023

    filename = f"{casename}_{year}_CHc_eventtotal_ens1.nc"

    ds = (xr.open_dataset(path / filename)
        .rename(dimx_N="lon", dimy_N="lat")["N"]
        .sum("time")
        .squeeze()
        .assign_coords(lat=np.arange(-90, 90.1, 0.25), lon=np.arange(-180, loncase, 0.25))
        .rename("LAGRANTO-WaterSip (CHc)"))
    
    return  ds.isel(lon=slice(0,1440))


def read_flexpart_univie(basedir, casename):
    """Read data for Flexpart UniVie."""
    print(f"Loading UniVie data for {casename}")
    path = basedir / casename / "results univie FLEXPART"
    filename = f"{casename.lower()}_univie.nc"

    ds = xr.open_dataset(path / filename).sum("time")
    combined = ds["moisture_uptakes_bl"] + ds["moisture_uptakes_ft"]

    return combined.rename("FLEXPART-WaterSip (UniVie)")


def read_2ldrm(basedir, casename):
    """Read data for 2ldrm."""
    print(f"Loading 2ldrm data for {casename}")
    path = basedir / casename / "results 2LDRM"
    filename = f"2LDRM_{casename}_case_gl.nc"

    ds = (
        xr.open_dataset(path / filename)
        .rename(latitude="lat", longitude="lon")["moisture_source"]
        .sum("time")
        .T.rename("2LDRM")
    )

    if casename == "Australia":
        ds.coords["lon"] = (ds["lon"] + 180) % 360 - 180
        ds = ds.sortby(ds.lon)

    return ds


def read_flexpart_uib(basedir, casename):
    """Read data for flexpart uib."""
    print(f"Loading UIB data for {casename}")
    if casename in ["Pakistan", "Australia"]:
        filename = f"{casename}_2022_UiB_Sodemann_grid_EN0_regridded.nc"
    elif casename == "Scotland":
        filename = f"{casename}_2023_UiB_Sodemann_grid_EN0_regridded.nc"

    path = basedir / casename / "results UiB FLEXPART WaterSip"
    ds_flexpart_uib = xr.open_dataset(path / filename)["moisture_uptakes"].rename("FLEXPART-WaterSip (UiB)")
    ds_flexpart_uib.coords['lon'] = (ds_flexpart_uib.coords['lon'] + 180) % 360 - 180
    ds_flexpart_uib = ds_flexpart_uib.sortby(ds_flexpart_uib.lon)
    return ds_flexpart_uib


def read_btrims(basedir, casename):
    """Read data for B-TrIMS."""
    print(f"Loading btrims data for {casename}")
    folder = "results_B-TrIMS" if casename == "Australia" else "results B-TrIMS"
    path = basedir / casename / folder

    file_pattern = path / f'bt.*.nc'
    files = sorted([f for f in glob.glob(str(file_pattern))])
    ds = xr.open_mfdataset(files, concat_dim="time", combine='nested').sum(dim="time")

    ds = xr.Dataset(
        data_vars={"wvcont": (["latitude", "longitude"], ds.wvcont.values)},
        coords={
            "latitude": (["latitude"], ds.latitude.values),
            "longitude": (["longitude"], ds.longitude.values),
        },
    )["wvcont"]
    ds.coords["longitude"] = (ds.coords["longitude"] + 180) % 360 - 180

    return (
        ds.sortby(ds.longitude)
        .rename(latitude="lat", longitude="lon")
        .rename("B-TrIMS")
    )


def read_data(basedir, casename):
    """Examples of data loading of moisture sources

    Data is loaded per individual ensemble member for each model.
    All data is converted to mm evaporative sources over the whole time period.
    """
    # TODO check completeness

    # Combine cumulative moisture sources for all models in one netcdf
    basedir = Path(basedir)

    return xr.merge(
        [
            read_wam2layers(basedir, casename),
            read_2ldrm(basedir, casename),
            read_utrack(basedir, casename),
            read_btrims(basedir, casename),
            read_tracmass(basedir, casename),
            read_ughent(basedir, casename),
            read_flexpart_uib(basedir, casename),
            read_flexpart_univie(basedir, casename)	,
            read_lagranto_chc(basedir, casename),
            read_flexpart_xu(basedir, casename),
            read_flexpart_tatfancheng(basedir, casename),
            read_uvigo(basedir, casename),
        ]
    )
    
def read_precip_era5(basedir, casename, exclude):
    A={}

    for model in ['results 2LDRM','results FLEXPART_WaterSip_TatFanCheng','results UGhent HAMSTER','results Utrack Arie Staal','results WRF-WVT','results B-TrIMS','results Ru_Xu_FLEXPART','results UiB FLEXPART WaterSip',
                  'results Uvigo','results CHc LAGRANTO','results TRACMASS Dipanjan Dey','results univie FLEXPART','results WAM2layers']:
    
        # Load and select variable for each model providing a timeline of the sum of ERA5 precipitation in the sink region as used in the diagnostic
        path=basedir+'/'+casename+'/'+model
        if model=='results 2LDRM': 
            filename='/'+casename+'_precip'
            variable='precip_era5'
            name='2LDRM'
        elif model=='results FLEXPART_WaterSip_TatFanCheng': 
            filename='/'+casename+'_precip_Ens1.nc'
            variable='precip_estimate'
            name='FLEXPART-WaterSip (TFC) Ens1'
        elif model=='results Utrack Arie Staal':
            if casename=='Pakistan': filename='/ERA5_input/'+casename+'_precip.nc'
            else: filename='/'+casename+'_precip.nc'
            variable='precip_era5'       
            name='UTrack Ens2'
        elif model=='results TRACMASS Dipanjan Dey':
            filename='/PR_ERA5_TRACMASS.nc'
            variable='PR_ERA5'
            name='TRACMASS'
        elif model=='results univie FLEXPART':
            filename='/'+casename.lower()+'_precip.nc'
            variable='precip_era5'
            name='FLEXPART-WaterSip (UniVie)'
        else: 
            filename='/'+casename+'_precip.nc'
            variable='precip_era5'
            if model=='results UGhent HAMSTER':name='FLEXPART-HAMSTER Ens5'
            elif model=='results WRF-WVT':name='WRF_WVT'
            elif model=='results B-TrIMS':
                name='B-TrIMS'
                if casename=='Australia':
                    path=basedir+'/'+casename+'/'+'results_B-TrIMS'
                else: 
                    path=basedir+'/'+casename+'/'+model
                    
            elif model=='results Ru_Xu_FLEXPART':name='FLEXPART-WaterSip (Xu)'
            elif model=='results UiB FLEXPART WaterSip':name='FLEXPART-WaterSip (UiB)'
            elif model=='results Uvigo':name='FLEXPART-LATTIN (UVigo)'
            elif model=='results CHc LAGRANTO':name='LAGRANTO-WaterSip (CHc)'
            elif model=='results WAM2layers':name='WAM2layers'
       
        print(model)
        if model not in exclude: #no precipitation timeline available (or not as mm over sink region)
            if model=='results CHc LAGRANTO':
                ds=xr.open_dataset(path+filename,decode_times=False)
                ds.hourssincestart.attrs["units"] = "hours since 2022-08-10"
                A[name] = xr.decode_cf(ds)[variable]
            elif model=='results Uvigo':
                ds=xr.open_dataset(path+filename,decode_times=True)
                if casename=='Pakistan':
                    a_gridcell_newp, l_ew_gridcellp, l_mid_gridcellp = get_grid_info_new(np.arange(24,30.1,0.25), np.arange(67,71.1,0.25))
                    A[name]=(ds['precip_era5'][:,240:265,988:1005]*a_gridcell_newp)/(a_gridcell_newp.sum()*17)
                elif casename=='Scotland':
                    a_gridcell_newp, l_ew_gridcellp, l_mid_gridcellp = get_grid_info_new(np.arange(52,60.1,0.25), np.arange(-8,-0.9,0.25))
                    A[name]=(ds['precip_era5'][:,120:153,688:717]*a_gridcell_newp)/(a_gridcell_newp.sum()*29)
                elif casename=='Australia':
                    a_gridcell_newp, l_ew_gridcellp, l_mid_gridcellp = get_grid_info_new(np.arange(-32,-21.9,0.25), np.arange(149,158.1,0.25))
                    A[name]=(ds['precip_era5'][:,448:489,1316:1353]*a_gridcell_newp)/(a_gridcell_newp.sum()*37)                
                A[name]=A[name].sum(['lon','lat'])
            else: 
                A[name]=xr.open_dataset(path+filename,decode_times=True)[variable]

    
    return (
        A
    )    
